{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prometheus\n",
    "\n",
    "随着`heapster`项目停止更新并慢慢被`metrics-server`取代，集群监控这项任务也将最终转移。`prometheus`的监控理念、数据结构设计其实相当精简，包括其非常灵活的查询语言；但是对于初学者来说，想要在k8s集群中实践搭建一套相对可用的部署却比较麻烦，由此还产生了不少专门的项目（如：[prometheus-operator](https://github.com/coreos/prometheus-operator)），本文介绍使用`helm chart`部署集群的prometheus监控。\n",
    "\n",
    "- `helm`已成为`CNCF`独立托管项目，预计会更加流行起来\n",
    "\n",
    "## 前提\n",
    "\n",
    "- 安装 helm：以本项目[安全安装helm](helm.md)为例\n",
    "- 安装 [kube-dns](kubedns.md)\n",
    "\n",
    "## 准备\n",
    "\n",
    "安装目录概览 `ll /etc/ansible/manifests/prometheus`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drwx------  3 root root  4096 Jun  3 22:42 grafana/\n",
    "-rw-r-----  1 root root 67875 Jun  4 22:47 grafana-dashboards.yaml\n",
    "-rw-r-----  1 root root   690 Jun  4 09:34 grafana-settings.yaml\n",
    "-rw-r-----  1 root root  1105 May 30 16:54 prom-alertrules.yaml\n",
    "-rw-r-----  1 root root   474 Jun  5 10:04 prom-alertsmanager.yaml\n",
    "drwx------  3 root root  4096 Jun  2 21:39 prometheus/\n",
    "-rw-r-----  1 root root   294 May 30 18:09 prom-settings.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 目录`prometheus/`和`grafana/`即官方的helm charts，可以使用`helm fetch --untar stable/prometheus` 和 `helm fetch --untar stable/grafana`下载，本安装不会修改任何官方charts里面的内容，这样方便以后跟踪charts版本的更新\n",
    "- `prom-settings.yaml`：个性化prometheus安装参数，比如禁用PV，禁用pushgateway，设置nodePort等\n",
    "- `prom-alertrules.yaml`：配置告警规则\n",
    "- `prom-alertsmanager.yaml`：配置告警邮箱设置等\n",
    "- `grafana-settings.yaml`：个性化grafana安装参数，比如用户名密码，datasources，dashboardProviders等\n",
    "- `grafana-dashboards.yaml`：预设置dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 安装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过　helm 部署　prometheus\n",
    "安装 prometheus chart，如果你的helm安装没有启用tls证书，请忽略--tls参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[root@wfh_deploy prometheus]#\n",
    "helm install --tls \\\n",
    "    --name monitor \\\n",
    "    --namespace monitoring \\\n",
    "    -f prom-settings.yaml \\\n",
    "    -f prom-alertsmanager.yaml \\\n",
    "    -f prom-alertrules.yaml \\\n",
    "    prometheus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error: context deadline exceeded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **错误原因：**\n",
    "我的部署主机与管理主机是分开的，而　helm\n",
    "分客户端和服务端，默认情况下，部署主机上只有　`helm　客户端`，因此不能直接在部署主机上使用配置文件来部署prometheus。\n",
    ">\n",
    "> **解决办法：**\n",
    "为了方便起见，我将　/etc/ansible/manifests/prometheus\n",
    "发送到　第一台管理主机上（我这里是wfh_node01)，然后在执行上面的指令即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在部署主机(wfh_deploy)执行：\n",
    "[root@wfh_deploy ~]#\n",
    "scp -r /etc/ansible/manifests/prometheus wfh_node01:~/\n",
    "\n",
    "# 切换到管理主机(wfh_node01)执行:\n",
    "[root@wfh_node01 ~]#\n",
    "cd prometheus\n",
    "helm install --tls \\\n",
    "    --name monitor \\\n",
    "    --namespace monitoring \\\n",
    "    -f prom-settings.yaml \\\n",
    "    -f prom-alertsmanager.yaml \\\n",
    "    -f prom-alertrules.yaml \\\n",
    "    prometheus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 输出结果：\n",
    "NAME:   monitor\n",
    "LAST DEPLOYED: Sun Sep  8 17:34:28 2019\n",
    "NAMESPACE:\n",
    "monitoring\n",
    "STATUS: DEPLOYED\n",
    "\n",
    "RESOURCES:\n",
    "==> v1/ConfigMap\n",
    "NAME\n",
    "DATA  AGE\n",
    "monitor-prometheus-alertmanager  1     31s\n",
    "monitor-prometheus-server\n",
    "3     31s\n",
    "\n",
    "==> v1/Pod(related)\n",
    "NAME\n",
    "READY  STATUS             RESTARTS  AGE\n",
    "monitor-prometheus-\n",
    "alertmanager-59cc5c4b6-vqlxf         0/2    ContainerCreating  0         31s\n",
    "monitor-prometheus-kube-state-metrics-7556696ff7-s88rc  0/1    ContainerCreating\n",
    "0         31s\n",
    "monitor-prometheus-node-exporter-fhq5t                  0/1\n",
    "ContainerCreating  0         30s\n",
    "monitor-prometheus-node-exporter-kn4qc\n",
    "1/1    Running            0         30s\n",
    "monitor-prometheus-node-exporter-pfbwq\n",
    "0/1    ContainerCreating  0         30s\n",
    "monitor-prometheus-node-exporter-phpf4\n",
    "1/1    Running            0         31s\n",
    "monitor-prometheus-node-exporter-r9vmr\n",
    "1/1    Running            0         30s\n",
    "monitor-prometheus-\n",
    "server-579954d46d-dpr5d              0/2    Init:0/1           0         30s\n",
    "==> v1/Service\n",
    "NAME                                   TYPE       CLUSTER-IP\n",
    "EXTERNAL-IP  PORT(S)       AGE\n",
    "monitor-prometheus-alertmanager        NodePort\n",
    "10.68.93.6    <none>       80:39001/TCP  31s\n",
    "monitor-prometheus-kube-state-\n",
    "metrics  ClusterIP  None          <none>       80/TCP        31s\n",
    "monitor-\n",
    "prometheus-node-exporter       ClusterIP  None          <none>       9100/TCP\n",
    "31s\n",
    "monitor-prometheus-server              NodePort   10.68.60.193  <none>\n",
    "80:39000/TCP  31s\n",
    "\n",
    "==> v1/ServiceAccount\n",
    "NAME\n",
    "SECRETS  AGE\n",
    "monitor-prometheus-alertmanager        1        31s\n",
    "monitor-\n",
    "prometheus-kube-state-metrics  1        31s\n",
    "monitor-prometheus-node-exporter\n",
    "1        31s\n",
    "monitor-prometheus-pushgateway         1        31s\n",
    "monitor-\n",
    "prometheus-server              1        31s\n",
    "\n",
    "==> v1beta1/ClusterRole\n",
    "NAME\n",
    "AGE\n",
    "monitor-prometheus-kube-state-metrics  31s\n",
    "monitor-prometheus-server\n",
    "31s\n",
    "\n",
    "==> v1beta1/ClusterRoleBinding\n",
    "NAME                                   AGE\n",
    "monitor-prometheus-kube-state-metrics  31s\n",
    "monitor-prometheus-server\n",
    "31s\n",
    "\n",
    "==> v1beta1/DaemonSet\n",
    "NAME                              DESIRED  CURRENT\n",
    "READY  UP-TO-DATE  AVAILABLE  NODE SELECTOR  AGE\n",
    "monitor-prometheus-node-\n",
    "exporter  5        5        3      5           3          <none>         31s\n",
    "==> v1beta1/Deployment\n",
    "NAME                                   READY  UP-TO-DATE\n",
    "AVAILABLE  AGE\n",
    "monitor-prometheus-alertmanager        0/1    1           0\n",
    "31s\n",
    "monitor-prometheus-kube-state-metrics  0/1    1           0          31s\n",
    "monitor-prometheus-server              0/1    1           0          31s\n",
    "NOTES:\n",
    "The Prometheus server can be accessed via port 80 on the following DNS\n",
    "name from within your cluster:\n",
    "monitor-prometheus-\n",
    "server.monitoring.svc.cluster.local\n",
    "\n",
    "\n",
    "Get the Prometheus server URL by running\n",
    "these commands in the same shell:\n",
    "  export NODE_PORT=$(kubectl get --namespace\n",
    "monitoring -o jsonpath=\"{.spec.ports[0].nodePort}\" services monitor-prometheus-\n",
    "server)\n",
    "  export NODE_IP=$(kubectl get nodes --namespace monitoring -o\n",
    "jsonpath=\"{.items[0].status.addresses[0].address}\")\n",
    "  echo\n",
    "http://$NODE_IP:$NODE_PORT\n",
    "#################################################################################\n",
    "######   WARNING: Persistence is disabled!!! You will lose your data when\n",
    "#####\n",
    "######            the Server pod is terminated.\n",
    "#####\n",
    "#################################################################################\n",
    "The Prometheus alertmanager can be accessed via port 80 on the following DNS\n",
    "name from within your cluster:\n",
    "monitor-prometheus-\n",
    "alertmanager.monitoring.svc.cluster.local\n",
    "\n",
    "\n",
    "Get the Alertmanager URL by running\n",
    "these commands in the same shell:\n",
    "  export NODE_PORT=$(kubectl get --namespace\n",
    "monitoring -o jsonpath=\"{.spec.ports[0].nodePort}\" services monitor-prometheus-\n",
    "alertmanager)\n",
    "  export NODE_IP=$(kubectl get nodes --namespace monitoring -o\n",
    "jsonpath=\"{.items[0].status.addresses[0].address}\")\n",
    "  echo\n",
    "http://$NODE_IP:$NODE_PORT\n",
    "#################################################################################\n",
    "######   WARNING: Persistence is disabled!!! You will lose your data when\n",
    "#####\n",
    "######            the AlertManager pod is terminated.\n",
    "#####\n",
    "#################################################################################\n",
    "For more information on running Prometheus, visit:\n",
    "https://prometheus.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过　helm 部署　grafana\n",
    "\n",
    "安装 grafana chart\n",
    "\n",
    "输入指令："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[root@wfh_node01 prometheus]#\n",
    "helm install --tls \\\n",
    ">     --name grafana \\\n",
    ">     --namespace monitoring \\\n",
    ">     -f grafana-settings.yaml \\\n",
    ">     -f grafana-dashboards.yaml \\\n",
    ">     grafana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 输出结果：\n",
    "NAME:   grafana\n",
    "LAST DEPLOYED: Sun Sep  8 18:07:57 2019\n",
    "NAMESPACE:\n",
    "monitoring\n",
    "STATUS: DEPLOYED\n",
    "\n",
    "RESOURCES:\n",
    "==> v1/ClusterRole\n",
    "NAME\n",
    "AGE\n",
    "grafana-clusterrole  31s\n",
    "\n",
    "==> v1/ClusterRoleBinding\n",
    "NAME\n",
    "AGE\n",
    "grafana-clusterrolebinding  31s\n",
    "\n",
    "==> v1/ConfigMap\n",
    "NAME\n",
    "DATA  AGE\n",
    "grafana                     4     31s\n",
    "grafana-dashboards-default  3\n",
    "31s\n",
    "\n",
    "==> v1/Pod(related)\n",
    "NAME                    READY  STATUS\n",
    "RESTARTS  AGE\n",
    "grafana-78747c76-n9zqd  0/1    PodInitializing  0         31s\n",
    "\n",
    "==>\n",
    "v1/Secret\n",
    "NAME     TYPE    DATA  AGE\n",
    "grafana  Opaque  3     31s\n",
    "\n",
    "==> v1/Service\n",
    "NAME     TYPE      CLUSTER-IP     EXTERNAL-IP  PORT(S)       AGE\n",
    "grafana\n",
    "NodePort  10.68.179.177  <none>       80:39002/TCP  31s\n",
    "\n",
    "==> v1/ServiceAccount\n",
    "NAME     SECRETS  AGE\n",
    "grafana  1        31s\n",
    "\n",
    "==> v1beta1/PodSecurityPolicy\n",
    "NAME\n",
    "PRIV   CAPS      SELINUX   RUNASUSER  FSGROUP   SUPGROUP  READONLYROOTFS\n",
    "VOLUMES\n",
    "grafana  false  RunAsAny  RunAsAny  RunAsAny   RunAsAny  false\n",
    "configMap,emptyDir,projected,secret,downwardAPI,persistentVolumeClaim\n",
    "\n",
    "==>\n",
    "v1beta1/Role\n",
    "NAME     AGE\n",
    "grafana  31s\n",
    "\n",
    "==> v1beta1/RoleBinding\n",
    "NAME     AGE\n",
    "grafana  31s\n",
    "\n",
    "==> v1beta2/Deployment\n",
    "NAME     READY  UP-TO-DATE  AVAILABLE  AGE\n",
    "grafana  0/1    1           0          31s\n",
    "\n",
    "\n",
    "NOTES:\n",
    "1. Get your 'admin' user\n",
    "password by running:\n",
    "\n",
    "   kubectl get secret --namespace monitoring grafana -o\n",
    "jsonpath=\"{.data.admin-password}\" | base64 --decode ; echo\n",
    "\n",
    "2. The Grafana\n",
    "server can be accessed via port 80 on the following DNS name from within your\n",
    "cluster:\n",
    "\n",
    "   grafana.monitoring.svc.cluster.local\n",
    "\n",
    "   Get the Grafana URL to\n",
    "visit by running these commands in the same shell:\n",
    "export NODE_PORT=$(kubectl\n",
    "get --namespace monitoring -o jsonpath=\"{.spec.ports[0].nodePort}\" services\n",
    "grafana)\n",
    "     export NODE_IP=$(kubectl get nodes --namespace monitoring -o\n",
    "jsonpath=\"{.items[0].status.addresses[0].address}\")\n",
    "     echo\n",
    "http://$NODE_IP:$NODE_PORT\n",
    "\n",
    "\n",
    "3. Login with the password from step 1 and the\n",
    "username: admin\n",
    "#################################################################################\n",
    "######   WARNING: Persistence is disabled!!! You will lose your data when\n",
    "#####\n",
    "######            the Grafana pod is terminated.\n",
    "#####\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [
      "bash"
     ],
     "id": ""
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 查看相关pod和svc\n",
    "$ kubectl get pod,svc -n monitoring \n",
    "NAME                                                     READY     STATUS    RESTARTS   AGE\n",
    "grafana-54dc76d47d-2mk55                                 1/1       Running   0          1m\n",
    "monitor-prometheus-alertmanager-6d9d9b5b96-w57bk         2/2       Running   0          2m\n",
    "monitor-prometheus-kube-state-metrics-69f5d56f49-fh9z7   1/1       Running   0          2m\n",
    "monitor-prometheus-node-exporter-55bwx                   1/1       Running   0          2m\n",
    "monitor-prometheus-node-exporter-k8sb2                   1/1       Running   0          2m\n",
    "monitor-prometheus-node-exporter-kxlr9                   1/1       Running   0          2m\n",
    "monitor-prometheus-node-exporter-r5dx8                   1/1       Running   0          2m\n",
    "monitor-prometheus-server-5ccfc77dff-8h9k6               2/2       Running   0          2m\n",
    "\n",
    "NAME                                    TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE\n",
    "grafana                                 NodePort    10.68.74.242   <none>        80:39002/TCP   1m\n",
    "monitor-prometheus-alertmanager         NodePort    10.68.69.105   <none>        80:39001/TCP   2m\n",
    "monitor-prometheus-kube-state-metrics   ClusterIP   None           <none>        80/TCP         2m\n",
    "monitor-prometheus-node-exporter        ClusterIP   None           <none>        9100/TCP       2m\n",
    "monitor-prometheus-server               NodePort    10.68.248.94   <none>        80:39000/TCP   2m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on 2019.09.11\n",
    "\n",
    "# 查看moniter的安装情况\n",
    "[root@wfh_node01 prometheus]# kubectl get pod,svc -n monitoring \n",
    "NAME                                                         READY   STATUS    RESTARTS   AGE\n",
    "pod/grafana-78747c76-hthxp                                   1/1     Running   0          8m43s\n",
    "pod/monitor-prometheus-alertmanager-59cc5c4b6-jw47g          2/2     Running   0          9m12s\n",
    "pod/monitor-prometheus-kube-state-metrics-7556696ff7-lklsm   1/1     Running   0          9m11s\n",
    "pod/monitor-prometheus-node-exporter-4btp2                   1/1     Running   0          9m12s\n",
    "pod/monitor-prometheus-node-exporter-8lt8f                   1/1     Running   0          9m12s\n",
    "pod/monitor-prometheus-node-exporter-pl7fk                   1/1     Running   0          9m11s\n",
    "pod/monitor-prometheus-node-exporter-wzfnx                   1/1     Running   0          9m12s\n",
    "pod/monitor-prometheus-node-exporter-z8qwr                   1/1     Running   0          9m11s\n",
    "pod/monitor-prometheus-server-579954d46d-z76x4               2/2     Running   0          9m11s\n",
    "\n",
    "NAME                                            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE\n",
    "service/grafana                                 NodePort    10.68.49.189    <none>        80:39002/TCP   8m44s\n",
    "service/monitor-prometheus-alertmanager         NodePort    10.68.14.31     <none>        80:39001/TCP   9m12s\n",
    "service/monitor-prometheus-kube-state-metrics   ClusterIP   None            <none>        80/TCP         9m12s\n",
    "service/monitor-prometheus-node-exporter        ClusterIP   None            <none>        9100/TCP       9m12s\n",
    "service/monitor-prometheus-server               NodePort    10.68.113.161   <none>        80:39000/TCP   9m12s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看主机网络访问信息\n",
    "[root@wfh_node01 prometheus]#\n",
    "export NODE_PORT=$(kubectl get --namespace monitoring -o jsonpath=\"{.spec.ports[0].nodePort}\" services monitor-prometheus-server)\n",
    "export NODE_IP=$(kubectl get nodes --namespace monitoring -o jsonpath=\"{.items[0].status.addresses[0].address}\")\n",
    "echo \"NODE_IP=\"$NODE_IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出结果：\n",
    "NODE_IP=192.168.20.201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 访问prometheus的web界面：`http://$NodeIP:39000`\n",
    "- 访问alertmanager的web界面：`http://$NodeIP:39001`\n",
    "- 访问grafana的web界面：`http://$NodeIP:39002` (默认用户密码 admin:admin，可在web界面修改)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 管理操作\n",
    "\n",
    "- 升级（修改配置）：修改配置请在`prom-settings.yaml` `prom-alertsmanager.yaml` 等文件中进行，保存后执行："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "[root@wfh_node01 prometheus]#\n",
    "# 修改prometheus\n",
    "helm upgrade --tls monitor \\\n",
    "    -f prom-settings.yaml \\\n",
    "    -f prom-alertsmanager.yaml \\\n",
    "    -f prom-alertrules.yaml \\\n",
    "    prometheus\n",
    "# 修改grafana\n",
    "helm upgrade --tls grafana \\\n",
    "    -f grafana-settings.yaml \\\n",
    "    -f grafana-dashboards.yaml \\\n",
    "    grafana\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 回退：具体可以参考`helm help rollback`文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ helm rollback --tls monitor [REVISION]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "$ helm del --tls monitor --purge\n",
    "$ helm del --tls grafana --purge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证告警\n",
    "\n",
    "- 修改`prom-alertsmanager.yaml`文件中邮件告警为有效的配置内容，并使用 helm upgrade更新安装\n",
    "-\n",
    "手动临时关闭 master 节点的 kubelet 服务，等待几分钟看是否有告警邮件发送"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在 master 节点运行\n",
    "$ systemctl stop kubelet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [可选] 配置钉钉告警\n",
    "\n",
    "- 创建钉钉群，获取群机器人 webhook 地址\n",
    "使用钉钉创建群聊以后可以方便设置群机器人，【群设置】-【群机器人】-【添加】-【自定义】-【添加】，然后按提示操作即可，参考 https://open-\n",
    "doc.dingtalk.com/docs/doc.htm?spm=a219a.7629140.0.0.666d4a97eCG7XA&treeId=257&articleId=105735&docType=1\n",
    "上述配置好群机器人，获得这个机器人对应的Webhook地址，记录下来，后续配置钉钉告警插件要用，格式如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://oapi.dingtalk.com/robot/send?access_token=xxxxxxxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 创建钉钉告警插件，参考 http://theo.im/blog/2017/10/16/release-prometheus-alertmanager-\n",
    "webhook-for-dingtalk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编辑修改文件中 access_token=xxxxxx 为上一步你获得的机器人认证 token\n",
    "$ vi /etc/ansible/manifests/prometheus/dingtalk-webhook.yaml\n",
    "# 运行插件\n",
    "$ kubectl apply -f /etc/ansible/manifests/prometheus/dingtalk-webhook.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 修改 alertsmanager 告警配置后，更新 helm prometheus 部署，成功后如上节测试告警发送"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改 alertsmanager 告警配置\n",
    "$ cd /etc/ansible/manifests/prometheus\n",
    "$ vi prom-alertsmanager.yaml\n",
    "# 增加 receiver dingtalk，然后在 route 配置使用 receiver: dingtalk\n",
    "    receivers:\n",
    "    - name: dingtalk\n",
    "      webhook_configs:\n",
    "      - send_resolved: false\n",
    "        url: http://webhook-dingtalk.monitoring.svc.cluster.local:8060/dingtalk/webhook1/send\n",
    "# ...\n",
    "# 更新 helm prometheus 部署\n",
    "$ helm upgrade --tls monitor -f prom-settings.yaml -f prom-alertsmanager.yaml -f prom-alertrules.yaml prometheus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下一步\n",
    "\n",
    "- 继续了解prometheus查询语言和配置文件\n",
    "- 继续了解prometheus告警规则，编写适合业务应用的告警规则\n",
    "-\n",
    "继续了解grafana的dashboard编写，本项目参考了部分[feisky的模板](https://grafana.com/orgs/feisky/dashboards)\n",
    "如果对以上部分有心得总结，欢迎分享贡献在项目中。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
